{
    "title": "실무로 통하는 ML 문제 해결 with 파이썬",
    "introduce": "216개 레시피로 실전 머신러닝 문제를 쉽고 빠르게 해결하기\n\n이 실용 가이드는 『파이썬을 활용한 머신러닝 쿡북』의 개정판으로, 현장에서 만날 수 있는 머신러닝 문제를 해결하는 데 도움이 될 200개 이상의 독립된 레시피를 제공한다. 파이썬과 판다스, 사이킷런을 포함한 라이브러리에 익숙하다면 데이터 로드부터 모델 훈련, 신경망 활용에 이르기까지 특정 문제를 해결할 수 있다. 이번 개정판의 각 레시피에는 토이 데이터셋으로 복사, 붙여넣기, 실행한 뒤 작동하는지 확인할 수 있는 코드가 포함되어 있다. 이때 사용 사례나 애플리케이션에 따라 이러한 레시피를 조정할 수 있다. 레시피에는 솔루션을 설명하고 유의미한 맥락을 제공하는 토론이 포함되어 있다. 이론과 개념을 넘어 실제 작동하는 머신러닝 애플리케이션을 구축하는 데 필요한 핵심을 배워보자.",
    "toc": "1장 벡터, 행렬, 배열\n_1.0 소개\n_1.1 벡터 만들기\n_1.2 행렬 만들기\n_1.3 희소 행렬 만들기\n_1.4 넘파이 배열 사전 할당하기\n_1.5 원소 선택하기\n_1.6 행렬 정보 확인하기\n_1.7 벡터화 연산 적용하기\n_1.8 최댓값, 최솟값 찾기\n_1.9 평균, 분산, 표준편차 계산하기\n_1.10 배열 크기 바꾸기\n_1.11 벡터나 행렬 전치하기\n_1.12 행렬 펼치기\n_1.13 행렬의 랭크 구하기\n_1.14 행렬의 대각원소 추출하기\n_1.15 행렬의 대각합 계산하기\n_1.16 점곱 계산하기\n_1.17 행렬 덧셈과 뺄셈\n_1.18 행렬 곱셈\n_1.19 역행렬\n_1.20 난수 생성하기\n\n\n_2.0 소개\n_2.1 샘플 데이터셋 적재하기\n_2.2 모의 데이터셋 만들기\n_2.3 CSV 파일 적재하기\n_2.4 엑셀 파일 적재하기\n_2.5 JSON 파일 적재하기\n_2.6 파케이 파일 적재하기\n_2.7 아브로 파일 적재하기\n_2.8 SQLite 데이터베이스로부터 적재하기\n_2.9 원격 SQL 데이터베이스에 쿼리하기\n_2.10 구글 시트에서 데이터 적재하기\n_2.11 S3 버킷에서 데이터 적재하기\n_2.12 비구조적인 데이터 적재하기\n\n\n_3.0 소개\n_3.1 데이터프레임 만들기\n_3.2 데이터에 대한 정보 확인하기\n_3.3 데이터프레임 슬라이싱하기\n_3.4 조건에 따라 행 선택하기\n_3.5 값 정렬하기\n_3.6 값 치환하기\n_3.7 열 이름 바꾸기\n_3.8 최솟값, 최댓값, 합, 평균 계산 및 개수 세기\n_3.9 고유한 값 찾기\n_3.10 누락된 값 다루기\n_3.11 열 삭제하기\n_3.12 행 삭제하기\n_3.13 중복된 행 삭제하기\n_3.14 값에 따라 행을 그룹핑하기\n_3.15 시간에 따라 행을 그룹핑하기\n_3.16 연산 집계와 통계\n_3.17 열 원소 순회하기\n_3.18 모든 열 원소에 함수 적용하기\n_3.19 그룹에 함수 적용하기\n_3.20 데이터프레임 연결하기\n_3.21 데이터프레임 병합하기\n\n\n_4.0 소개\n_4.1 특성 스케일 바꾸기\n_4.2 특성 표준화하기\n_4.3 정규화하기\n_4.4 다항 특성과 교차항 특성 생성하기\n_4.5 특성 변환하기\n_4.6 이상치 감지하기\n_4.7 이상치 다루기\n_4.8 특성 이산화하기\n_4.9 군집으로 샘플을 그룹으로 묶기\n_4.10 누락된 값을 가진 샘플 삭제하기\n_4.11 누락된 값 채우기\n\n\n_5.0 소개\n_5.1 순서가 없는 범주형 특성 인코딩하기\n_5.2 순서가 있는 범주형 특성 인코딩하기\n_5.3 특성 딕셔너리 인코딩하기\n_5.4 누락된 클래스 값 대체하기\n_5.5 불균형한 클래스 다루기\n\n\n_6.0 소개\n_6.1 텍스트 정제하기\n_6.2 HTML 파싱과 정제하기\n_6.3 구두점 삭제하기\n_6.4 텍스트 토큰화하기\n_6.5 불용어 삭제하기\n_6.6 어간 추출하기\n_6.7 품사 태깅하기\n_6.8 개체명 인식 수행하기\n_6.9 텍스트를 BoW로 인코딩하기\n_6.10 단어 중요도에 가중치 부여하기\n_6.11 텍스트 벡터를 사용해 검색 쿼리 텍스트의 유사도 계산하기\n_6.12 감성 분석 분류기 사용하기\n\n\n_7.0 소개\n_7.1 문자열을 날짜로 변환하기\n_7.2 시간대 다루기\n_7.3 날짜와 시간 선택하기\n_7.4 날짜 데이터를 여러 특성으로 나누기\n_7.5 날짜 간의 차이 계산하기\n_7.6 요일 인코딩하기\n_7.7 시차 특성 만들기\n_7.8 이동 시간 윈도 사용하기\n_7.9 시계열 데이터에서 누락된 값 다루기\n\n\n_8.0 소개\n_8.1 이미지 로드하기\n_8.2 이미지 저장하기\n_8.3 이미지 크기 변경하기\n_8.4 이미지 자르기\n_8.5 이미지 흐리게 하기\n_8.6 이미지 선명하게 하기\n_8.7 대비 높이기\n_8.8 색깔 구분하기\n_8.9 이미지 이진화하기\n_8.10 배경 제거하기\n_8.11 윤곽선 감지하기\n_8.12 모서리 감지하기\n_8.13 머신러닝 특성 만들기\n_8.14 컬러 히스토그램을 특성으로 인코딩하기\n_8.15 사전 훈련된 임베딩을 특성으로 사용하기\n_8.16 OpenCV로 객체 탐지하기\n_8.17 파이토치로 이미지 분류하기\n\n\n_9.0 소개\n_9.1 주성분을 사용해 특성 줄이기\n_9.2 선형적으로 구분되지 않은 데이터의 차원 축소하기\n_9.3 클래스 분리를 최대화하여 특성 줄이기\n_9.4 행렬 분해를 사용하여 특성 줄이기\n_9.5 희소한 데이터의 특성 줄이기\n\n\n_10.0 소개\n_10.1 분산을 기준으로 수치 특성 선택하기\n_10.2 분산을 기준으로 이진 특성 선택하기\n_10.3 상관관계가 큰 특성 다루기\n_10.4 분류 작업에 관련 없는 특성 삭제하기\n_10.5 재귀적 특성 제거하기\n\n\n_11.0 소개\n_11.1 교차검증 모델 만들기\n_11.2 기본 회귀 모델 만들기\n_11.3 기본 분류 모델 만들기\n_11.4 이진 분류기의 예측 평가하기\n_11.5 이진 분류기 임곗값 평가하기\n_11.6 다중클래스 분류기 예측 평가하기\n_11.7 분류기 성능 시각화하기\n_11.8 회귀 모델 평가하기\n_11.9 군집 모델 평가하기\n_11.10 사용자 정의 평가 지표 만들기\n_11.11 훈련 세트 크기에 따른 영향 시각화하기\n_11.12 평가 지표 리포트 만들기\n_11.13 하이퍼파라미터 값의 영향 시각화하기\n\n\n_12.0 소개\n_12.1 완전 탐색을 사용해 최선의 모델 선택하기\n_12.2 랜덤 탐색을 사용해 최선의 모델 선택하기\n_12.3 여러 학습 알고리즘에서 최선의 모델 선택하기\n_12.4 전처리와 함께 최선의 모델 선택하기\n_12.5 병렬화로 모델 선택 속도 높이기\n_12.6 알고리즘에 특화된 기법을 사용해 모델 선택 수행 속도 높이기\n_12.7 모델 선택 후 성능 평가하기\n\n\n_13.0 소개\n_13.1 직선 학습하기\n_13.2 교차 특성 다루기\n_13.3 비선형 관계 학습하기\n_13.4 규제로 분산 줄이기\n_13.5 라소 회귀로 특성 줄이기\n\n\n_14.0 소개\n_14.1 결정 트리 분류기 훈련하기\n_14.2 결정 트리 회귀 훈련하기\n_14.3 결정 트리 모델 시각화하기\n_14.4 랜덤 포레스트 분류기 훈련하기\n_14.5 랜덤 포레스트 회귀 훈련하기\n_14.6 OOB 데이터로 랜덤 포레스트 평가하기\n_14.7 랜덤 포레스트에서 중요한 특성 구분하기\n_14.8 랜덤 포레스트에서 중요한 특성 선택하기\n_14.9 불균형한 클래스 다루기\n_14.10 트리 크기 제어하기\n_14.11 부스팅을 사용해 성능 향상하기\n_14.12 XGBoost 모델 훈련하기\n_14.13 LightGBM으로 실시간 성능 향상하기\n\n\n_15.0 소개\n_15.1 샘플의 최근접 이웃 찾기\n_15.2 k-최근접 이웃 분류기 만들기\n_15.3 최선의 이웃 개수 결정하기\n_15.4 반지름 기반의 최근접 이웃 분류기 만들기\n_15.5 근사 최근접 이웃 찾기\n_15.6 근사 최근접 이웃 평가하기\n\n\n_16.0 소개\n_16.1 이진 분류기 훈련하기\n_16.2 다중 클래스 분류기 훈련하기\n_16.3 규제로 분산 줄이기\n_16.4 대용량 데이터에서 분류기 훈련하기\n_16.5 불균형한 클래스 다루기\n\n\n_17.0 소개\n_17.1 선형 분류기 훈련하기\n_17.2 커널을 사용해 선형적으로 구분되지 않는 클래스 다루기\n_17.3 예측 확률 계산하기\n_17.4 서포트 벡터 식별하기\n_17.5 불균형한 클래스 다루기\n\n\n_18.0 소개\n_18.1 연속적인 특성으로 분류기 훈련하기\n_18.2 이산적인 카운트 특성으로 분류기 훈련하기\n_18.3 이진 특성으로 나이브 베이즈 분류기 훈련하기\n_18.4 예측 확률 보정하기\n\n\n_19.0 소개\n_19.1 k-평균을 사용한 군집\n_19.2 k-평균 군집 속도 향상하기\n_19.3 평균이동을 사용한 군집\n_19.4 DBSCAN을 사용한 군집\n_19.5 계층적 병합을 사용한 군집\n\n\n_20.0 소개\n_20.1 텐서 만들기\n_20.2 넘파이로 텐서 만들기\n_20.3 희소 텐서 만들기\n_20.4 텐서 원소 선택하기\n_20.5 텐서 구조 파악하기\n_20.6 원소에 연산 적용하기\n_20.7 최댓값과 최솟값 찾기\n_20.8 텐서 크기 바꾸기\n_20.9 텐서 전치하기\n_20.10 텐서 펼치기\n_20.11 점곱 계산하기\n_20.12 텐서 곱셈\n\n\n_21.0 소개\n_21.1 파이토치 자동미분 사용하기\n_21.2 신경망을 위해 데이터 전처리하기\n_21.3 신경망 구성하기\n_21.4 이진 분류기 훈련하기\n_21.5 다중 분류기 훈련하기\n_21.6 회귀 모델 훈련하기\n_21.7 예측하기\n_21.8 훈련 기록 시각화하기\n_21.9 가중치 규제로 과대적합 줄이기\n_21.10 조기 종료로 과대적합 줄이기\n_21.11 드롭아웃으로 과대적합 줄이기\n_21.12 모델 훈련 진행 과정 저장하기\n_21.13 신경망 튜닝하기\n_21.14 신경망 시각화하기\n\n\n_22.0 소개\n_22.1 이미지 분류 신경망 훈련하기\n_22.2 텍스트 분류 신경망 훈련하기\n_22.3 이미지 분류를 위해 사전 훈련된 모델 미세 튜닝하기\n_22.4 텍스트 분류를 위해 사전 훈련된 모델 미세 튜닝하기\n\n\n_23.0 소개\n_23.1 사이킷런 모델 저장하고 로드하기\n_23.2 텐서플로 모델 저장하고 로드하기\n_23.3 파이토치 모델 저장하고 로드하기\n_23.4 사이킷런 모델 서빙하기\n_23.5 텐서플로 모델 서빙하기\n_23.6 셀던으로 파이토치 모델 서빙하기\n\n찾아보기"
}