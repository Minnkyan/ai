{
    "title": "쉽고 빠르게 익히는 실전 LLM",
    "introduce": "LLM 입문자도 당장 시작할 수 있게 해 주는 단계별 가이드\nLLM FAQ, AI/ML 용어 해설집, LLM 애플리케이션 개발 고려사항 Tip 수록\n\n이 책은 LLM 개발 단계별 지침, 모범 사례, 실제 사례 연구, 실습 예제 등 LLM이 생소했던 사람도 당장 개발을 시작할 수 있을 만큼 LLM에 대한 전반적인 지식을 쉽고 친절하게 설명한다. 또한, LLM 개발에 더 깊이 들어가 파인튜닝, 오픈 소스와 클로즈드 소스 LLM의 비교 및 활용법, 데이터 형식 및 파라미터 설정법, 임베딩, 성능 최적화, 고급 프롬프트 엔지니어링까지 다뤄 LLM을 실제로 현업에서 활용하고 있는 실무자에게도 통찰력을 제공한다. LLM 입문서이자, 실무 가이드인 이 도서를 통해 다가오는 LLM 시대를 더 확실히 대비하자!",
    "toc": "Part 1 LLM 소개\n\nChapter 1 LLM\n_1.1 LLM이란?\n__1.1.1 LLM 정의\n__1.1.2 LLM 주요 특징\n__1.1.3 LLM 작동 원리\n_1.2 현재 많이 사용되는 LLM\n__1.2.1 BERT\n__1.2.2 GPT-4와 ChatGPT\n__1.2.3 T5\n_1.3 도메인 특화 LLM\n_1.4 LLM을 이용한 애플리케이션\n__1.4.1 전통적인 자연어 처리(NLP) 작업\n__1.4.2 자유로운 텍스트 생성\n__1.4.3 정보 검색/신경망 의미 기반 검색\n__1.4.4 챗봇\n_1.5 마치며\n\nChapter 2 LLM을 이용한 의미 기반 검색\n_2.1 들어가는 글\n_2.2 작업\n__2.2.1 비대칭적 의미 기반 검색\n_2.3 솔루션 개요\n_2.4 구성 요소\n__2.4.1 텍스트 임베더\n__2.4.2 문서 청킹\n__2.4.3 벡터 데이터베이스\n__2.4.4 파인콘\n__2.4.5 오픈 소스 대안\n__2.4.6 검색 결과 재순위화\n__2.4.7 API\n_2.5 통합\n__2.5.1 성능\n_2.6 클로즈드 소스 구성 요소의 비용\n_2.7 마치며\n\nChapter 3 프롬프트 엔지니어링의 첫 번째 단계\n_3.1 들어가는 글\n_3.2 프롬프트 엔지니어링\n__3.2.1 언어 모델에서 정렬\n__3.2.2 직접 요청하기\n__3.2.3 퓨샷 학습\n__3.2.4 출력 구조화\n__3.2.5 페르소나 지정하기\n_3.3 여러 모델과 프롬프트 작업하기\n__3.3.1 ChatGPT\n__3.3.2 Cohere\n__3.3.3 오픈 소스 프롬프트 엔지니어링\n_3.4 ChatGPT와 Q/A 챗봇 만들기\n_3.5 마치며\n\n\n\nChapter 4 맞춤형 파인튜닝으로 LLM을 최적화하기\n_4.1 들어가는 글\n_4.2 파인튜닝과 전이학습: 기초 안내서\n__4.2.1 파인튜닝 과정\n__4.2.2 파운데이션 모델로 사전 훈련된 클로즈드 소스 모델 사용하기\n_4.3 OpenAI 파인튜닝 API 살펴보기\n__4.3.1 GPT-3 파인튜닝 API\n__4.3.2 사례 연구: Amazon 리뷰 감정 분류\n__4.3.3 데이터에 대한 지침 및 모범 사례\n_4.4 OpenAI CLI로 맞춤형 예제 준비하기\n_4.5 OpenAI CLI 설정하기\n__4.5.1 하이퍼파라미터 선택과 최적화\n_4.6 첫 번째 파인튜닝 LLM\n__4.6.1 정량적 지표로 파인튜닝 모델 평가하기\n__4.6.2 정성적 평가 기술\n__4.6.3 파인튜닝된 GPT-3 모델을 애플리케이션에 통합하기\n_4.7 사례 연구 2: Amazon 리뷰 카테고리 분류\n_4.8 마치며\n\nChapter 5 고급 프롬프트 엔지니어링\n_5.1 들어가는 글\n_5.2 프롬프트 인젝션 공격\n_5.3 입력/출력 유효성 검사\n__5.3.1 예제: NLI 이용해서 유효성 검사 파이프라인 만들기\n_5.4 배치 프롬프팅\n_5.5 프롬프트 체이닝\n__5.5.1 프롬프트 인젝션을 방어하기 위한 체이닝\n__5.5.2 프롬프트 스터핑을 막기 위한 체이닝\n__5.5.3 예제: 멀티모달 LLM을 안전하게 사용하기 위한 체이닝\n_5.6 연쇄적 사고 프롬프트\n__5.6.1 예시: 기초 연산\n_5.7 퓨샷 학습 다시 보기\n__5.7.1 예제: LLM을 이용한 초등학교 수학\n_5.8 테스트와 반복적 프롬프트 개발\n_5.9 마치며\n\nChapter 6 임베딩과 모델 아키텍처 맞춤화\n_6.1 들어가는 글\n_6.2 사례 연구: 추천 시스템 만들기\n__6.2.1 문제와 데이터 설정하기\n__6.2.2 추천의 문제 정의하기\n__6.2.3 추천 시스템의 전체 개요\n__6.2.4 항목 비교를 위한 맞춤형 설명 필드 생성\n__6.2.5 파운데이션 임베더로 기준선 설정\n__6.2.6 파인튜닝 데이터 준비\n__6.2.7 문장 트랜스포머 라이브러리로 오픈 소스 임베더 파인튜닝하기\n__6.2.8 결과 요약\n_6.3 마치며\n\n\n\nChapter 7 파운데이션 모델을 넘어서\n_7.1 들어가는 글\n_7.2 사례연구: VQA\n__7.2.1 모델 소개: ViT, GPT-2 및 DistillBERT\n__7.2.2 은닉 상태 투영과 융합\n__7.2.3 크로스-어텐션: 이것은 무엇이며 왜 중요한가요?\n__7.2.4 맞춤형 멀티모달 모델\n__7.2.5 데이터: Visual QA\n__7.2.6 VQA 훈련 과정\n__7.2.7 결과 요약\n_7.3 사례 연구: 피드백 기반 강화 학습\n__7.3.1 모델: FLAN-T5\n__7.3.2 보상 모델: 감정과 문법 정확도\n__7.3.3 트랜스포머 강화 학습\n__7.3.4 RLF 훈련 과정\n__7.3.5 결과 요약\n_7.4 마치며\n\nChapter 8 고급 오픈 소스 LLM 파인튜닝\n_8.1 들어가는 글\n_8.2 예시: BERT를 이용한 애니메이션 장르 다중 레이블 분류\n__8.2.1 다중 레이블 장르 예측을 위한 성능 측정 지표로 자카드 점수 사용하기\n__8.2.2 단순 파인튜닝 과정\n__8.2.3 오픈 소스 LLM 파인튜닝을 위한 일반적인 팁\n__8.2.4 결과 요약\n_8.3 예시: GPT-2를 이용한 LaTeX 생성\n__8.3.1 오픈 소스 모델을 위한 프롬프트 엔지니어링\n__8.3.2 결과 요약\n_8.4 시난의 현명하면서도 매력적인 답변 생성기: SAWYER\n__1단계: 지시사항 파인튜닝\n__2단계: 보상 모델 훈련\n__3단계: (예상하는) 사용자 피드백 기반 강화 학습\n__결과 요약\n_8.5 끊임없이 변화하는 파인튜닝의 세계\n_8.6 마치며\n\nChapter 9 LLM을 프로덕션 환경에서 사용하기\n_9.1 들어가는 글\n_9.2 클로즈드 소스 LLM을 프로덕션 환경에 배포하기\n__9.2.1 비용 예측\n__9.2.2 API 키 관리\n_9.3 프로덕션 환경에 오픈 소스 LLM 배포하기\n__9.3.1 추론을 위한 모델 준비\n__9.3.2 상호 운용성\n__9.3.3 양자화\n__9.3.4 가지치기\n__9.3.5 지식 증류\n__9.3.6 LLM 사용에 대한 비용 예측\n__9.3.7 Hugging Face에 올리기\n_9.4 마치며\n\n\n\nAPPENDIX A LLM 자주 묻는 질문(FAQ)\nAPPENDIX B LLM 용어 해설\nAPPENDIX C LLM 애플리케이션 개발 고려사항"
}